import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

class LogicGateNN:
    def __init__(self, input_size=2, hidden_size=2, output_size=1, learning_rate=0.1, epochs=10000):
        np.random.seed(42)
        self.lr = learning_rate
        self.epochs = epochs
        self.W1 = np.random.uniform(size=(input_size, hidden_size))
        self.b1 = np.random.uniform(size=(1, hidden_size))
        self.W2 = np.random.uniform(size=(hidden_size, output_size))
        self.b2 = np.random.uniform(size=(1, output_size))

    def train(self, X, y):
        for epoch in range(self.epochs):
            hidden = sigmoid(np.dot(X, self.W1) + self.b1)
            output = sigmoid(np.dot(hidden, self.W2) + self.b2)

            error = y - output
            d_output = error * sigmoid_derivative(output)
            d_hidden = np.dot(d_output, self.W2.T) * sigmoid_derivative(hidden)

            self.W2 += np.dot(hidden.T, d_output) * self.lr
            self.b2 += np.sum(d_output, axis=0, keepdims=True) * self.lr
            self.W1 += np.dot(X.T, d_hidden) * self.lr
            self.b1 += np.sum(d_hidden, axis=0, keepdims=True) * self.lr

            if epoch % 2000 == 0:
                print(f"Epoch {epoch}, Loss: {np.mean(np.square(error)):.4f}")

        return output

if __name__ == "__main__":
    X = np.array([[0, 0],
                  [0, 1],
                  [1, 0],
                  [1, 1]])

    gate = input("Enter gate (AND / OR / XOR): ").strip().upper()

    outputs = {
        "AND": [[0], [0], [0], [1]],
        "OR": [[0], [1], [1], [1]],
        "XOR": [[0], [1], [1], [0]]
    }

    if gate not in outputs:
        print("Invalid gate! Defaulting to XOR.")
        gate = "XOR"

    y = np.array(outputs[gate])

    model = LogicGateNN()
    preds = model.train(X, y)

    print(f"\nFinal Predictions for {gate} gate:")
    print(np.round(preds, 3))
